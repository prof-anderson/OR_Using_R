\mainmatter

# Introduction

```{r, eval=FALSE, include=FALSE}
library(bookdown); library(rmarkdown); rmarkdown::render("01-Introduction.Rmd", "pdf_book")
```

```{r Ch1setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(tidy = F)
knitr::opts_chunk$set(cache = TRUE)
library(knitr)
library(kableExtra)
```

## What is Operations Research

Operations Research is the application of mathematics and scientific approaches to decision making. It is a field deeply connected with applications. \vspace{12pt}

The field of Operations Research has strong roots in World War II as nations and militaries urgently tried to best make use of their resources and capabilities. Leaders asked people from various disciplines to help improve a variety of problems such as submarine hunting, mining of resources, and production planning. Essentially, these tools are scientific approaches for making decisions for the design and operation of a system with limited resources. The tools that that they used came from combining applied math and scientific approaches resulting in tremendous improvements. \vspace{12pt}

After the war, many of the same approaches were also then used for business applications. Military groups most commonly used the term Operations Research while business groups often used the term Management Science. \vspace{12pt}

Neither term, Operations Research nor Management Science is perfect. Operations Research is often confused with the strongly overlapping area of Operations Management and also the word research implies to some that it is strictly theoretical. Conversely, Management Science might imply that the rest of management is non-scientific or that it is just limited to business applications. In this book, we will use the term Operations Research to mean both Operations Research and Management Science as well as often abbreviate it as OR. \vspace{12pt}

## Purpose of this Book

There are many comprehensive introductions to Operations Research available [@hillier2020] [@winston2003], and others. In the past, I had emphasized a spreadsheet-centric based introduction to operations research such as [@RagsdaleSpreadsheetModelingDecision2017] and [@baker2015] which had the side benefit of also encouraging better spreadsheet usage practices. Unfortunately the spreadsheet metaphor constrains the reader's perspective often leading people to tie models to closely to the data analyzed, specific dimensions of a particular problem, and the rows/columns construct often prevents people from thinking of richer problems. A more rigorous and tool agnostic coverage of optimization can be beneficial, for example, Tovey's recent book stands out [@tovey]. The goal of this book is to provide a timely introduction to Operations Research using a powerful open source tool, R. It was written to support the ETM 540/640 Operations Research course at Portland State University which is taught on a quarter basis for people without a background in Operations Research or R. As such the current scope is limited to what can be readily accomplished in a 10 week quarter, giving an introduction to the tools and methods available. There are many other Operations Research tools available besides R. \vspace{12pt}

This book is meant to be a hybrid, both serving as an introduction to R and to Operations Research in the context of optimization. \vspace{12pt}

You can always access the current version of this book on Github. <https://github.com/prof-anderson/OR_Using_R>

## Range of Operations Research Techniques

Operations Research covers many different techniques. They can be classified in a wide range of ways. Some of the more common approaches are:

-   Optimization
-   Simulation
-   Queuing Theory
-   Markov Chains
-   Inventory Control
-   Forecasting
-   Game Theory
-   Decision Theory

Each of these topics can require a full graduate level class or more to cover. In particular, Optimization and Simulation can be further subdivided into separate sub areas that represent entire specialties of their own. In this book, we currently limit ourselves to the field of Optimization for this current book. The interested reader is welcome to explore each area further. \vspace{12pt}

Analysis methods are typically characterized as either descriptive prescriptive. A descriptive technique would be one that describes the current state of the system. A prescriptive technique is one that would prescribe a certain course of action to achieve a desired outcome. For example, weather forecasting is a very sophisticated descriptive discipline since we don't generally have control over short term weather. On the other hand, if we were to look at intervention approaches such as cloud seeding we might try to come up a prescriptive application. Prescriptive applications are abundant and can often be wherever decisions need to be made. \vspace{12pt}

## Relationship between Operations Research and Analytics

The field of Operations Research significantly predates that of the term analytics but they are closely linked. This is strongly demonstrated by the leading professional organization for operations research, INFORMS (The Institute for Operations Research and Management Science), developing a professional certification for analytics. This certification process had leadership from industry representing the diverse users of Operations Research techniques. \vspace{12pt}

## Why R?

This book adopts the platform of R for doing operations research and analytics. R is a popular, open source programming language developed by statisticians, originally as an open source alternative to the statistics language S. As such, it has very strong numerical methods implementations. Given the open source nature, it has been popular for researchers and many of these researchers have written their own packages to extend the functionality of R. These packages cover a tremendously broad range of topics and well over 16,000 are available from CRAN (the Comprehensive R Archive Network) as of December, 2020. \vspace{12pt}

In about 2012, my Extreme Technology Analytics Research Group was facing a decision. We had been using proprietary analytics tools for years but had problems with software licensing and the limited range of specialized languages. We wanted a single platform that could do both statistics and optimization, was freely available with no ongoing license renewal, and was readily extensible. \vspace{12pt}

In the end, we debated between Python and R. While R grew out from statisticians to encompass broader areas, Python grew from a general purpose programming language to add features to address a broad range of different application areas including statistics. While they both have deep roots with over 20 years of active development, this also means that aspects of their original designs are somewhat dated and carry forward the burden of legacies of past decisions when computers were more limited and the meaning of a big dataset would have been much smaller. \vspace{12pt}

Python had some advantages from the optimization side while R had advantages from the statistical side. In the end, we chose R because Python's numerical methods capabilities were not quite as rich. Since that time, both R and Python have significantly matured. \vspace{12pt}

As time has gone by, R has developed robust toolsets such as RStudio making it more powerful and easier to use. R's extensive package community has become so diverse and powerful that proprietary statistics software such as SPSS and JMP now promote that they can use R packages. The result is that R is still a great choice for analysts and code developed for R should be usable for a long time. \vspace{12pt}

As should be expected, new tools continue to arise. In particular, Julia is a new, modern language developed around numerical analysis. Industry adoption of Julia is far behind R and Python given their head start of multiple decades. Even if Julia or some other environment does someday become more popular, skills developed using R will be readily transferable and provide an excellent foundation for learning new languages. \vspace{12pt}

A PhD student that I knew was preparing for his final defense and did a practice presentation with his advisor and a professor. He was proud of a well polished 250 page thesis with dozens of tables of numerical results. The analysis included dozens of regressions, all with similar form and dependent variables. The professor asked him why his dependent variables was the number of projects rather than projects per year. The student thought for a moment and realized that all of his analysis needed to be redone. This would take days or weeks if he had used a GUI based tool. Using R he did a search and replace for the dependent variable, cross-checked results, and met the next day to update that professor and his advisor of the new (and much better!) results. He successfully defended his thesis a couple weeks later.

## Conventions Used in this Book

I've adopted the following conventions in this book.

-   R code fragments, including packages will be denoted using monospaced text such as adding two R data objects `a+b`.\
-   Mathematical symbols and equations will be italicized. For example, if two variables are mathematical symbols and being added, then it would be *a+b*.\
-   Tables of information and code fragments are provided liberally and at times erring on the side of being repetitious to assist in interpretation and reproducing analyses.\
-   There may be more efficient ways of performing operations but the focus is on readability.

\vspace{12pt}

This book is continuing to be updated. Comments, suggestions, and corrections are welcome.

## Getting Started with R

A quick getting started with R will be helpful. I strongly recommend using RStudio. There are a lot of online resources for getting started with R, for example, *A Modern Dive* is a web book on using R and refreshing statistics that is very helpful with a corresponding traditional book [@IsmayIntroductionStatisticalData]. I also like books such as *R in a Nutshell* [@AdlerNutshell2012] or *R in Action* [@KabacoffActionDataAnalysis2011]. \vspace{12pt}

I usually find the best way for me to learn a new tool is to roll up my sleeves and jump right in. This book can be approached in that way - just be ready for a little more experimentation. This book is available on Github and the R Markdown files are available for use. Code fragments are shown quite liberally for demonstrating how things work. While this may be a bit verbose it is meant to enable readers to jump in at various points of the book. \vspace{12pt}

While code fragments can be copied from the R markdown files for this book, it is often best to physically retype many of the code fragments shown as that gives time to reflect on what each statement is doing. \vspace{12pt}

Let's define some conventions to be used throughout the book. First, let me be clear, the goal of this section is not to provide a comprehensive introduction to R. Entire books are written on that subject. My goal here is to simply make sure that everyone can get started productively in the material covered later.

Since this book is focused on using R for operations research, we will focus on the capabilities that are needed for this area and introduce additional features and functions as needed. If you are already comfortable with R, RStudio, and RMarkdown, you may skip the remainder of this section. \vspace{12pt}

Begin by ensuring that you have access to or installed R and RStudio. Both are available for Windows, Mac, and Linux operating systems as well as being available as web services. \vspace{12pt}

Now, let's assume that you are running RStudio. \vspace{12pt}

In this book, I will frequently show code fragments called chunks to show R code. In general, these code chunks can be run by simply retyping the command(s) in the Console. \vspace{12pt}

```{r Assigning}
a <- 7
```

This command assigns the value of 7 to the variable *a*. It is standard in R to use `<-` as an assignment operator rather than an equals sign. We can then use R to process this information. \vspace{12pt}

```{r Math-operation}
6*a
```

Yes, not surprisingly, *6\*7* is *42*. Notice that if we don't assign that result to something, it gives an immediate result to the screen. \vspace{12pt}

We will often be using or defining data that has more than one element. In fact, R is designed around more complex data structures. Let's go ahead and define a matrix of data. \vspace{12pt}

```{r Create-Matrix}
b<-matrix(c(1,2,3,4,5,6,7,8))
```

By default, it is assuming that the matrix has one column which means that every data value is in a separate row. The `c` function is a concatenate operator meaning that it combines all the following items together. \vspace{12pt}

Let's look at *b* now to see what it contains. \vspace{12pt}

```{r Looking-at-an-Object}
b
```

Let's instead define this matrix to have four columns and two rows. \vspace{12pt}

```{r Resizing-Matrix}
b<-matrix(c(1,2,3,4,5,6,7,8), ncol=4)
b
```

Notice that since there are eight elements, we only needed to tell R that the matrix has four columns and it then knew that there would be only two rows. Of course we could have set the number of rows to be two for the same result. \vspace{12pt}

This is still a little ambiguous. Let's give the rows and columns names. For now we will simply name them Row and Col. \vspace{12pt}

```{r Naming-Rows-and-Columns}
b<-matrix(c(1,2,3,4,5,6,7,8), ncol=4, 
          dimnames=c(list(c("Row1", "Row2")),
                     list(c("Col1", "Col2","Col3","Col4"))))
```

::: {.remark name="RStudio Console"}
The RStudio console can save typing by pressing the up arrow key to view previous command(s) which can then be further edited.
:::

\vspace{12pt}

Okay, this command has a lot more going on. The term `dimnames` is a parameter that contain names for rows and columns. One thing to note is that this line fills up more space than a single line so it rolls over to multiple line.

The `dimnames` parameter will get get two concatenated (combined) lists. The first list is a combined list of two text strings "Row1" and "Row2". The next line does the same for columns. \vspace{12pt}

Let's confirm that it works. \vspace{12pt}

```{r Displaying-New-Matrix}
b
```

This table is still not that "nice" looking. Let's use a package that does a nicer job of formatting tables. To do this, we will use an extra package. Up to this point, everything that we have done just simply uses standard built in functions of R. The package that we will use is `kable` but there are plenty of others available such as `pander`, `kable`, `xtable`, and `huxtable`. While `kable` is a function of `knitr`, it is significantly enhanced by the `kableExtra` package. Let's start by loading the `kableExtra` package. \vspace{12pt}

```{r Loading-a-Package}
library (kableExtra)
```

If R indicates that you don't have the `kableExtra` package installed on your computer, you can press the "Install" command under the Packages tab and then type in `kableExtra` or use the `install.packages` command from RStudio.  The `kbl` is a shorthand way of entering the `kable` function that is provided by `kableExtra`.

\vspace{12pt}

Notice the hash symbol is used to mark comment in the above code chunk. It is also used to "comment out" a command that I don't need to use at the current time. Using comments to explain what a command is doing can be helpful to anyone that needs to revisit your code in the future, including yourself! \vspace{12pt}

```{r Using-kable}
knitr::kable (b, booktabs=T, 
     caption="Example using Kable with booktabs") |>
  kableExtra::kable_styling(latex_options = "hold_position")
```

The table looks very nice in the book.  Let's explain in detail how the table is generated.  This code chunk has a lot going and is worth a careful look.

* The first line `knitr::kable` means that we should run the `kable` function from within `knitr`.  In general, as a long as the library is loaded and the same function is not defined by two different loaded libraries, you don't need to specify where the function is being run from.  
* The `booktabs=T` sets a format for clean published table style by setting the option to `T` for `TRUE`.
* The second line provides a caption. 
* The last part of the second line warrants a little attention.  It is the new pipe operator and requires `R` version 4.1.0 or higher.  The pipe operator basically says pass this commands output into the beginning of the next command.  We'll use it a lot for table generation.  Prior to R version 4.1.0, people that used pipes in R often used the `%>%` operator from a separate package such as `magrittr`.  For most users, including us, the built-in `|>` will suffice.
* The last command, `kable_styling`, holds the position and keeps LaTeX from second guessing where the ideal location would be for the table. Note that is also specifying its source package, in this case, `kableExtra`. There are a lot of other options in `kable_styling` that we will use in later chapters as needed.
* For your own use, you could shorten all of this to just `kable (b)`. On the other hand, `kableExtra` has one more small trick up its sleeve. It provides a shorter name for the `kable` function of just `kbl`.  When space is at premium, this shortcut is handy. It also serves as a helpful check to ensure that `kableExtra` is loaded.

Let's continue experimenting with operators. \vspace{12pt}

```{r Scalar-Multiplication}
c<-a*b
kbl(c, booktabs=T,
    caption= "Scalar Multiplication of Matrix b") |>
  kable_styling(latex_options = "hold_position")
```

Now let's do a transpose operation on the original matrix. What this means that it converts rows into columns and columns into rows. \vspace{12pt}

```{r Transposing}
d<-t(b)
kbl (d, booktabs=T,
     caption = "Transposition of Matrix b") |>
  kable_styling(latex_options = "hold_position")
```

Oops, notice that row and column names are also transposed. The result is that we now have rows labeled as columns and columns labeled as rows! 

Now we have done some basic operations within R. Try your hand at the following exercises.

**Exercise 1.1** (Changing Row and Column Names). Change the row and column names for the transposed matrix above.

Here is my solution to that.

```{marginfigure}
Oops.  Still not right.  Need to do some more.
```

```{r Displaying-My-Solution}
c
d
```

Assume that your company's product has a demand of 10 widgets on Monday, increasing by five units for every day through Sunday. Create a matrix where the column indicates that the day of the week and the row is the product name.

Recall that we have created a variety of objects now: a, b, c, and d. R provides a lot of tools for slicing, dicing, and combining data.

```{r Original-Matrix}
kbl (b, booktabs=T,
     caption="Original Matrix b") |>
  kable_styling(latex_options = "hold_position")
```

Let's look at the original matrix, b and what we can do with it. Let's grab the second row, third column and last element.

```{r Extracting-Second-Row}
temp1 <- as.matrix(b[2,])
kbl (temp1, booktabs=T,
     caption = "Second Row of b") |>
  kable_styling(latex_options = "hold_position")
```

The `as.matrix` function is used to convert the object into a matrix so that `kable` can display it well.

```{r Extracting-Third-Column}
temp2 <- as.matrix(b[,3])
kbl (temp2, booktabs=T,
       caption="Third Column of b") |>
  kable_styling(latex_options = "hold_position")
```


Grabbing the third column is not terribly interesting but operations such as this will often be quite useful.

```{r Bottom-Right-Element}
temp3 <- as.matrix(b[2,4]) 
kbl (temp3, booktabs=T,
     caption="Last Element of b") |>
  kable_styling(latex_options = "hold_position")
```


A table made up of just one element is even less profound but is again useful. Now, let's show how we can combine two objects.\
Recall tables *b* and *c* from earlier.

```{r Show-both-Matrices, echo=FALSE}
kbl (b, caption="Matrix b") |>
  kable_styling(latex_options = "hold_position")
kbl (c, caption="Matrix c") |>
  kable_styling(latex_options = "hold_position")
```

Let's take the first row of `b` and combine it with the second row of `c` to form a new matrix, `e`. Since these are rows that are going to be combined, we will use a command, `rbind`, to bind these rows together.

```{r Combined-Matrix}
temp4 <- rbind(b[1,],c[2,])
kbl (temp4, booktabs=T,
     caption="Combined Matrix") |>
  kable_styling(latex_options = "hold_position")
```

Notice that *temp4* has inherited the column names but lost the row names. Let's set the row names for this matrix.

```{r Changing-Row-Names }
rownames(temp4)<-list("From b", "From c")
kbl (temp4, booktabs=T,
     caption="Combined Matrix with Explanation of Source") |>
  kable_styling(latex_options = "hold_position")
```

\vspace{12pt}

We could combine all of matrix `b` and matrix `c` together using row binding or column binding. Table 1.10 will bind using columns. \vspace{12pt}

```{r Row-and-Column-Binding }
temp5<- cbind(b,c)
kbl (temp5, booktabs=T, 
     caption="Column Binding of Matrices b and c") |>
  kable_styling(latex_options = "hold_position")
```

\vspace{12pt}

And Table 1.11 will use rows as binding condition.

```{r Row-and-Column-Binding2, fig.margin=TRUE}
temp6 <- rbind(b,c)
kbl (temp6, booktabs=T,
       caption="Row Binding of Matrices b and c") |>
  kable_styling(latex_options = "hold_position")
```

Data organizing is a less glamorous part of the job for practicing analytics professionals but can consume a majority of the workday. There is a lot more that can be said about data wrestling but scripting the data cleansing in terms R commands will make the work more repeatable, consistent, and in the end save time.

::: {.exercise name="Creating a Matrix of Daily Demand for Four Weeks"}
Assume that your company's product has a demand of 10 widgets on Monday, increasing by five units for every day through Sunday. Build a matrix of four weeks of demand where each row is a separate week. Each Monday starts over with the same demand. The rows should be named Week1, Week2, etc. The columns should have names corresponding to the day of the week.
:::

::: {.exercise name="Creating a Matrix of Demand for Two Products"}
Assume that your company's product has a demand of 10 widgets on Monday, increasing by five units for every day through Sunday. Gadgets have a demand of 20 on Monday, increasing by 3 units a day through Sunday. Build a matrix showing each product as a separate row. Rows should have names for the products and columns for the days of the week.
:::
