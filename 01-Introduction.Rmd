---
title: "Introduction to Operations Research"
author: "Tim Anderson"
date: "11/23/2018"
output: 
  tufte::tufte_handout: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction 

## What is Operations Research

Operations Research is the application of mathematics and scientific approaches to decision making. It is a field deeply connected with applications.  

The field of Operations Research has strong roots in World War II as nations and militaries urgently tried to best make use of their resources and capabilities.  Leaders asked people from various disciplines to help improve  a variety of problems such as submarine hunting, mining of resources, and production planning. Essentially, these tools are scientific approaches for making decisions for the design and operation of a system with limited resources. The tools that that they used came from combining applied math and scientific approaches resulting in tremendous improvements.  

After the war, many of the same approaches were also then used for business applications.  Military groups most commonly used the term Operations Research while business groups often used the term Management Science.  

Neither term, Operations Research nor Management Science is perfect. Operations Research is often confused with the strongly overlapping area of Operations Management and also the word research implies to some that it is strictly theoretical.  Conversely, Management Science might imply that the rest of management is non-scientific or that it is just limited to business applications.  In this book, we will use the term Operations Research to mean both Operations Research and Management Science as well as often abbreviate it as OR.  

## Purpose of this Book

There are many comprehensive introductions to Operations Research available including classics from Hillier and Lieberman, Winston, and others. The goal of this book is to provide a timely introduction to Operations Research using a powerful open source tool, R. It was written to support the ETM 540/640 Operations Research course at Portland State University which is taught on a quarter basis for people without a background in Operations Research or R. As such the current scope is limited to what can be readily accomplished in a 10 week quarter.  There are many other Operations Research tools available.  

This book is meant to be a hybrid, both serving as an introduction to R and to Operations Research.  

A quick getting started with R will be helpful.  I strongly recommend using RStudio.  _A Modern Dive_ is a web book on using R and refreshing statistics that is very helpful [@IsmayIntroductionStatisticalData].  I also like books such as R in a Nutshell [@AdlerNutshell2012] or R in Action [@KabacoffActionDataAnalysis2011].

I usually find the best way for me to learn a new tool is to roll up my sleeves and jump right in.  Hence the book can be approached in that way and just be ready for a little more experimentation.  This book is available on Github and the R Markdown files are available for use.  Code fragments are shown quite liberally for demonstrating how things work.  While this may be a bit verbose and at times repetitious, it is meant to help people jump in at various points of the book.  

While code fragments can be copied from the R markdown files for this book, it is often best to physically retype many of the code fragments shown as that gives time to reflect on what each statement is doing.  

## Range of Operations Research Techinques

Operations Research covers many different techniques.  They can be classified in a wide range of ways.  Some of the more common approaches are:

* Optimization
* Simulation
* Queuing Theory
* Markov Chains
* Inventory Control
* Forecasting
* Game Theory
* Decision Theory

Each of these topics can require a full graduate level class or more to cover. In particular, Optimization and Simulation can be further subdivided into separate sub areas that represent entire specialties of their own. In this book, we currently limit ourselves to the field of Optimization for this current book.  The interested reader is welcome to explore each area further.  

Analysis methods are typically characterized as either descriptive  prescriptive.  A descriptive technique would be one that describes the current state of the system.  A prescriptive technique is one that would prescribe a certain course of action to achieve a desired outcome.  For example, weather forecasting is a very sophisticated descriptive discipline since we don't generally have control over short term weather.  On the other hand, if we were to look at intervention approaches such as cloud seeding we might try to come up a prescriptive application.  Prescriptive applications are abundant and can often be wherever decisions need to be made.

## Relationship between Operations Research and Analytics

The field of Operations Research significantly predates that of the term analytics but they are closely linked.  This is strongly demonstrated by the leading professional organization for operations research, INFORMS (The Institute for Operations Research and Management Science), developing a professional certification for analytics.  This certification process had leadership from industry representing the diverse users of Operations Research techniques.  

## Why R?

This book adopts the platform of R for doing operations research and analytics. R is a popular, open source programming language developed by statisticians, originally as an open source alternative to the statistics language S.  As such, it has very strong numerical methods implementations.  Given the open source nature, it has been popular for researchers and many of these researchers have written their own packages to extend the functionality of R. These packages cover a tremendously broad range of topics and well over 10,000 are available from CRAN (the Comprehensive R Archive Network).  

In about 2012, my Extreme Technology Analytics Research Group was facing a decision.  We had been using proprietary analytics tools for years but had problems with software licensing and the limited reach of specialized languages.  We wanted a single platform that could do both statistics and optimization, was freely available with no ongoing license renewal, and was readily extensible. 

In the end, we debated between Python and R. While R grew out from statisticians to encompass broader areas, Python grew from a general purpose programming language to add features to address a broad range of different application areas including statistics. While they both have deep roots with over 20 years of active development, this also means that aspects of their original designs are somewhat dated and carry forward the burden of legacies of past decisions when computers were more limited and the meaning of a big dataset would have been much smaller.  

Python had some advantages from the optimization side while R had advantages from the statistical side. In the end, we chose R because Python's numerical methods were not quite as rich. Since that time, both R and Python have significantly matured. 

As time has gone by, R has developed robust toolsets such as RStudio to making R more powerful and easier to use. R's extensive package community has become so diverse and powerful that in fact proprietary statistics software such as SPSS and JMP now promote that they can use R packages. The result is that R is still a great choice for analysts and code developed for R should be usable for a long time.  

As should be expected, new tools continue to arise. In particular, Julia is a new, modern language developed around numerical analysis. Industry adoption of Julia is far behind R and Python given their head start of multiple decades. Even if Julia or some other environment does someday become more popular, skills developed using R will be readily transferable and provide an excellent foundation for learning new languages. 

## Conventions Used in this Book

I've adopted the following conventions in this book.  

* R code fragments, including packages will be denoted using monospaced text such as adding two R data objects `a+b`.
* Mathematical symbols and equations will be italicized.  For example, if two variables are mathematical symbols and being added, then it would be _a+b_.  
* Tables of information and code fragments are provided liberally and at times erring on the side of repetitious to assist in interpretation and reproducing analyses.
* There may be more efficient ways of performing operations but the focus is on readability.  

This book is continuing to be updated. Comments, suggestions, and corrections are welcome.

## Getting Started with R

Let's get started with R and explain some conventions to be used throughout the book.  First, let me be clear, the goal of this section is not to provide a comprehensive introduction to R.  Entire books are written on that subject. My goal here is to simply make sure that everyone can get started productively in the material covered later.

Since this book is focused on using R for operations research, we will focus on the capabilities that are needed for this area and introduce additional features and functions as needed. If you are already comfortable with R, RStudio, and RMarkdown, you may skip the remainder of this section.

Begin by ensuring that you have access to or installed R and RStudio.  Both are available for Windows, Mac, and Linux operating systems as well as being available as web services.

Now, let's assume that you are running RStudio.  

In this book, I  will frequently show code fragments called chunks to show R code. In general, these code chunks can be run by simply retyping the command(s) in the Console.  

```{r Assigning}
a <- 7
```

This command assigns the value of 7 to the variable _a_. It is standard in R to use `<-` as an assignment operator rather than an equals sign. We can then use R to process this information. 

```{r Math_operation}
6*a
```

Yes, not surprisingly, _6*7_ is _42_.  Notice that if we don't assign that result to something, it gives an immediate result to the screen.  

We will often be using or defining data that has more than one element.  In fact, R is designed around more complex data structures.  Let's go ahead and define a matrix of data.  

```{r Create_Matrix}
b<-matrix(c(1,2,3,4,5,6,7,8))
```

By default, it is assuming that the matrix has one column which means that every data value is in a separate row.  The `c` function is a concatenate operator meaning that it combines all the following items together.  

Let's look at _b_ now to see what it contains.

```{r Looking_at_an_Object}
b
```

Let's instead define this matrix to have four columns and two rows.

```{r Resizing_Matrix}
b<-matrix(c(1,2,3,4,5,6,7,8), ncol=4)
b
```

Notice that we only needed to tell R that the matrix has four columns and it then knew that there two rows.  We could have set the number of rows to be two for the same result.  

This is still a little boring.  Let's give the rows and columns names.  

```{r Naming_Rows_and_Columns}
b<-matrix(c(1,2,3,4,5,6,7,8), ncol=4, 
          dimnames=c(list(c("Row1", "Row2")),
                     list(c("Col1", "Col2","Col3","Col4"))))
```

Okay, this command has a lot more going on.  The term `dimnames` is a parameter that contain names for rows and columns.  One thing to note is that this line fills up more space than a single line so it rolls over to multiple line.  

The `dimnames` parameter will get get two concatenated (combined) lists. The first list is a combined list of two text strings "Row1" and "Row2". The next line does the same for columns.  

Let's confirm that it works.

```{r Displaying_New_Matrix}
b
```

This table is still not that "nice" looking.  Let's use a package that does a nicer job of formatting tables.  To do this, we will use an extra package.  Up to this point, everything that we have done just simply uses standard built in functions of R. The package that we will use is `pander` but there are plenty of others available such as `kable`,`xtable`, and `huxtable`.  Let's start by loading the package.

```{r Installing_a_Package}
# install.packages("pander") # Use this command if pander is not installed.
library(pander)
```

If R indicates that you don't have pander installed on your computer, you can  press the "Install" command under the Packages tab and then type in pander or use the `install.packages` command.  

Notice the hash symbol is used to mark comment in the above code chunk.  It is also used to "comment out" a command that I don't need to use at the current time.  Using comments to explain what a command is doing can be helpful to anyone that needs to revisit your code in the future, including yourself!  

Now, let's put the `pander` package to work.

```{marginfigure}
When rendered in plain text, it might not look so fancy but it looks much better when a report is generated using knitr into html or as a pdf.  If you are viewing this output in a formatted output, the results will be very visible.]
```

```{r Using_Pander, echo=FALSE}
pander(b, caption="Nicely formatted table using pander")
```

Let's continue experimenting with operators.  

```{r Scalar_Multiplication}
c<-a*b
pander(c, caption="Scalar Multiplication of Matrix b")
```

Now let's do a transpose operation on the original matrix.  What this means that it converts rows into columns and columns into rows.

```{r Transposing}
d<-t(b)
pander(d, caption="Transposition of Matrix b")
```

Woops, notice that row and column names are also transposed.  The result is that we now have rows labeled as columns and columns labeled as rows!  

Now we have done some basic operations within R. Try your hand at the following exercises.

```{exercise, name="Changing Row and Column Names"}
Change the row and column names for the transposed matrix above.   
```

Here is my solution to that...
```{marginfigure}
Oops..  Still not right.  Need to do some more...
```

```{r Displaying_My_Solution}
c
d
```

Assume that your company's product has a demand of 10 widgets on Monday, increasing by five units for every day through Sunday.  Create a matrix where the column indicates that the day of the week and the row is the product name.

Recall that we have created a variety of objects now: a, b, c, and d. R provides a lot of tools for slicing, dicing, and combining data.  

Let's look at the original matrix, b and what we can do with it.  Let's grab the second row, third column and last element.  

```{r Original_Matrix}
pander(b, caption="Original Matrix b")
```

```{r Extracting_Second_Row}
pander(as.matrix(b[2,]), caption="Second Row of b")
```

The `as.matrix` function is used to convert the object into a matrix so that pander can display it well.  Note that I might explore alternatives to `pander` such as `huxtable` in the future.  Here is a discussion of huxtable and comparison of many different packages for displaying tables https://hughjonesd.github.io/huxtable/design-principles.html 

```{r Extracting_Third_Column}
pander(as.matrix(b[,3]), caption="Third Column of b")
```

Grabbing the third column is not terribly interesting but operations such as this will often be quite useful.

```{r Displaying Bottom_Right_Element}
pander(as.matrix(b[2,4]), caption="Last Element of b")
```

A table made up of just one element is even less profound but is again useful. Now, let's show how we can combine two objects.  
Recall tables _b_ and _c_ from earlier.

```{r Show_both_Matrices}
pander(b, caption="Matrix b")
pander(c, caption="Matrix c")
```

Let's take the first row of `b` and combine it with the second row of `c` to form a new matrix, `e`.  Since these are rows that are going to be combined, we will use a command, `rbind`, to bind these rows together.

```{r Combined_Matrix}
e<-rbind(b[1,],c[2,])
pander(e,caption="Combined Matrix")
```

Notice that _e_ has inherited the column names but lost the row names.  Let's set the row names for this matrix.

```{r Changing_Row_Names}
rownames(e)<-list("From_b", "From_c")
pander(e, caption="Combined Matrix with Explanation of Source")
```

We could combine all of matrix `b` and matrix `c` together using row binding or column binding.

```{r Row_and_Column_Binding}
pander(cbind(b,c), caption="Column Binding of Matrices b and c")
pander(rbind(b,c), caption="Row Binding of Matrices b and c")
```

Data organizing is a less glamorous part of the job for practicing analytics professionals but can consume a majority of the workday. There is a lot more that can be said about data wrestling but scripting the data cleansing in terms R commands will make the work more repeatable, consistent, and in the end save time.

```{marginfigure}
A PhD student that I knew was preparing for his final defense and did a practice presentation with his advisor and a professor. He was proud of a well polished 250 page thesis with dozens of tables of numerical results.  The analysis included dozens of regressions, all with similar form and dependent variables. The professor asked him why his dependent variables was the number of projects rather than projects per year. The student thought for a moment and realized that all of his analysis needed to be redone. This would take days or weeks if he had used a GUI based tool. Using R he did a search and replace for the dependent variable, cross-checked results, and met the next day to update that professor and his advisor of the new (and much better!) results. He successfully defended his thesis a couple weeks later.
```
\vspace{12pt}
***Excercise:*** "Creating a Matrix of Daily Demand for Four Weeks"
Assume that your company's product has a demand of 10 widgets on Monday, increasing by five units for every day through Sunday. Build a matrix of four weeks of demand where each row is a separate week.     
\vspace{12pt}
***Exercise:*** "Creating a Matrix of Demand for Two Products" 
Assume that your company's product has a demand of 10 widgets on Monday, increasing by five units for every day through Sunday. Gadgets have a demand of 20 on Monday, increasing by 3 units a day through Sunday. Build a matrix showing each product as a separate row.


